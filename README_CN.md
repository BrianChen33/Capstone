# Capstone – 室内蓝牙定位原型系统

## 1. 背景与问题陈述
室内定位技术已成为智能建筑、资产追踪、无人零售和安防等应用的关键。与拥有 GPS 的室外环境不同，室内空间充满了反射、遮挡和复杂的结构，导致信道高度动态化，对定位精度、稳定性和实时性提出了更严格的要求。在现有技术中，蓝牙因其低成本、低功耗和易于部署的特点，已成为工业界和学术界的重要选择。然而，传统的蓝牙定位方法受限于信号强度的巨大波动，难以在复杂场景中实现稳定的亚米级或更高精度。

近年来，聚焦于相位和到达角（AoA）的阵列技术以及深度学习推动了室内定位性能的前沿。iArk 平台通过“大规模天线阵列 + 侧信道”实现了与协议无关的相位估计和空间构建，支持跨协议的高精度 AoA 和三角测量，显著减轻了多径干扰，并提供了一种工程可行的硬件和中间件解决方案（An et al., 2020）。在算法层面，Zhao et al. (2024) 进一步将 Transformer 引入定位任务，利用 A-子网络学习 AoA，T-子网络学习三角测量和运动上下文，并利用预训练模型 LocGPT 支持跨场景迁移，大幅降低了数据需求和部署成本。这两条分别来自系统和算法的工作路线，验证了“空间谱 + 深度学习”在复杂室内环境中的优越性。

基于这些进展，本项目聚焦于以下核心问题：在多网关蓝牙 AoA 获取下，深度学习模型如何有效表示高维空间谱并进行多视角融合，以在复杂多径环境中实现稳定、可复现且实时的的高精度定位？为解决这一问题，本项目必须系统地应对四个挑战：（1）由多径干扰和距离衰减引起的观测混叠；（2）高维空间谱的表示学习和时间上下文建模；（3）多网关空间几何对定位可观测性和鲁棒性的影响；（4）跨场景泛化与工程实时性之间的权衡。

本项目的意义在于提出并验证一种基于蓝牙成本和功耗优势的端到端“空间谱驱动”深度学习解决方案。它将融合 iArk 的空间谱构建理念，并引入基于 Transformer 的多视角融合和上下文建模，有望在不需要昂贵的超宽带（UWB）或复杂硬件修改的情况下，显著提高室内定位的精度、鲁棒性和可部署性。

## 2. 目标与预期成果
本项目旨在实现以下目标：
1.	**数据与机制理解**：系统分析蓝牙空间谱的统计特性，可视化多径及其与精度的关系，并量化网关数量、位置和方向性对可观测性的影响。
2.	**模型设计与实现**：构建并比较多种深度学习定位模型；在受控规模下，借鉴 A-子网络/T-子网络的分工，形成“先 AoA，后三角测量”的分层架构。
3.	**端到端评估**：在给定数据集上进行训练和测试；评估定位误差（平均值/中位数/第90百分位）、推理延迟和吞吐量。
4.	**方法论比较与建议**：与传统几何方法和 CNN/MLP 基准进行比较；为工程实践提供推荐配置和部署指南。

预期成果包括：（1）一个可复现的基于深度学习的蓝牙室内定位原型（包括数据处理、训练/推理和可视化工具链）；（2）一份量化报告和可视化结果，为不同场景提供配置建议和经验总结。

## 3. 实施现状
本节详细介绍了核心组件的当前实现情况，对应于项目方法论的初始阶段。

### 3.1 数据集分析 (Dataset Analysis)
**目标**：理解原始数据的统计特性。
**实现**：
- **脚本**：`train.py` -> `analyze_dataset` 函数。
- **方法**：脚本加载原始张量 `[N, 1, 986]` 并计算特征通道（前 984 列）和目标坐标（最后 2 列）的全局统计信息。
- **指标**：样本数量、特征维度、特征的均值、标准差、最小值/最大值，以及坐标的边界框。
- **输出**：结果保存至 `artifacts/dataset_stats.json`。

### 3.2 数据预处理分析 (Preprocessing Dataset Analysis)
**目标**：为稳定的模型训练准备数据。
**实现**：
- **脚本**：`train.py` -> `BluetoothPositioningDataset` 类和 `make_datasets` 函数。
- **方法**：
    - **标准化**：对特征应用 Z-score 标准化：$x' = \frac{x - \mu}{\sigma}$。均值 ($\mu$) 和标准差 ($\sigma$) 仅从训练集计算，并应用于验证/测试集以防止数据泄露。
    - **划分**：`make_datasets` 函数使用固定的随机种子 (42) 将训练张量随机划分为 80% 的训练集和 20% 的验证集，以确保可复现性。

### 3.3 网络架构选择 (Network Architecture Selection)
**目标**：建立坐标回归的基准模型。
**实现**：
- **脚本**：`train.py` -> `SimpleRegressor` 类。
- **架构**：多层感知机 (MLP) 基准。
    - **输入**：984 维空间谱特征。
    - **隐藏层**：
        - 线性层 (984 -> 256) + ReLU
        - Dropout (0.1) 用于正则化
        - 线性层 (256 -> 128) + ReLU
    - **输出**：线性层 (128 -> 2) 代表 (x, y) 坐标。
- **理由**：MLP 作为一个稳健的基准，用于在探索 CNN 或 Transformer 等复杂架构之前验证流程。

### 3.4 初步建模 (Preliminary Modeling)
**目标**：训练基准模型并评估性能。
**实现**：
- **脚本**：`train.py` -> `train` 和 `evaluate` 函数。
- **训练循环**：
    - **优化器**：Adam (`lr=1e-3`)。
    - **损失函数**：均方误差 (MSE)。
    - **过程**：迭代固定数量的轮次（默认 5 轮）。跟踪训练损失和验证集 MSE/MAE。
    - **检查点**：将验证集 MSE 最低的模型状态保存到 `artifacts/best_model.pt`。
- **评估**：在保留的测试集 (`test_data-s02-80-20-seq1.pt`) 上进行最终评估，指标保存至 `artifacts/metrics.json`。

## 4. 未来规划

### 4.1 模型训练与调优
**计划**：
- **超参数优化**：使用网格搜索或贝叶斯优化系统地调整学习率、批量大小和 Dropout 率。
- **高级架构**：
    - **CNN**：实现 1D CNN 以捕获空间谱中的局部相关性。
    - **Transformer**：实现“先 AoA，后三角测量”架构，使用 Transformer 编码器对空间谱的全局上下文进行建模。
- **正则化**：尝试权重衰减和不同的 Dropout 策略以提高泛化能力。

### 4.2 实验设计
**计划**：
- **交叉验证**：实现 k-折交叉验证以确保结果的稳健性。
- **消融研究**：分析不同特征子集（例如，特定频段或天线）的影响。
- **比较**：将深度学习方法与传统的几何三角测量方法进行比较。
- **可视化**：开发工具以可视化预测轨迹与真实轨迹的对比，识别误差模式（例如，角落情况、多径严重区域）。

## 5. 安装与使用
运行快速冒烟测试（根据需要调整 epochs/batch size）：

```bash
python train.py --epochs 5 --batch-size 64 --lr 1e-3 \
  --train-path train_data-s02-80-20-seq1.pt \
  --test-path test_data-s02-80-20-seq1.pt \
  --output-dir artifacts
```
如果您的 PyTorch 版本早于支持 `weights_only=True`，请添加 `--allow-unsafe-load`（仅针对受信任的 `.pt` 文件）。

主要 CLI 选项：
- `--epochs`: 训练轮次（默认 5）。
- `--batch-size`: 批量大小（默认 64）。
- `--lr`: 学习率（默认 1e-3）。
- `--val-ratio`: 从训练张量中划分验证集的比例（默认 0.2）。

脚本将打印数据集统计信息、每轮验证指标、最终测试 MSE/MAE，并将生成的文件写入选定的输出目录。

## 模型训练、调优与实验设计
- **数据划分**：使用内置的 80/20 训练/验证划分进行早停；保留提供的测试张量仅用于最终评估。
- **超参数调优**：学习率 (1e-4–5e-3)、批量大小 (32–256)、Dropout (0.0–0.3)、隐藏层宽度 (128–512) 和轮次（配合验证集 MSE 早停）。
- **特征处理**：保留最后两个张量值作为回归目标；仅使用训练统计数据对特征列进行标准化。
- **指标**：跟踪 MSE（优化目标）和 MAE（可解释性）。比较验证曲线以检测过拟合。
- **扩展**：如果需要更大容量，可以将 `SimpleRegressor` 替换为更深的 MLP、针对 984 长度频谱的 1D CNN，或用于空间谱建模的轻量级 Transformer 编码器。
